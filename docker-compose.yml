# =============================================================================
# neuro-bitnet Docker Compose
# Multi-model: Falcon3-7B-Instruct-1.58bit / BitNet-b1.58-2B-4T
# Seleccionar modelo: BITNET_MODEL=falcon-7b docker compose up
# Puerto: 11435 (para coexistir con Ollama en 11434)
# =============================================================================

services:
  bitnet:
    container_name: neuro-bitnet
    # Usar imagen pre-construida de Docker Hub
    # Modelos disponibles: bitnet-2b (default), falcon-7b
    image: madkoding/neuro-bitnet:${BITNET_MODEL:-bitnet-2b}
    
    # Para build local, descomentar:
    # build:
    #   context: .
    #   dockerfile: Dockerfile
    #   args:
    #     MODEL_VARIANT: ${BITNET_MODEL:-bitnet-2b}
    
    # GPU NVIDIA
    runtime: nvidia
    
    environment:
      # GPU
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
      
      # Servidor BitNet
      - BITNET_HOST=0.0.0.0
      - BITNET_PORT=8080
      - BITNET_CTX_SIZE=${BITNET_CTX_SIZE:-4096}
      - BITNET_PARALLEL=${BITNET_PARALLEL:-4}
      - BITNET_GPU_LAYERS=${BITNET_GPU_LAYERS:-99}
      - BITNET_THREADS=${BITNET_THREADS:-4}
      # Model path se configura automáticamente en la imagen
      
      # HuggingFace (opcional, para modelos gated)
      - HF_TOKEN=${HF_TOKEN:-}
    
    # Reservar GPU
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    
    # Volúmenes (opcional, solo para persistencia de logs/cache)
    # El modelo ya está incluido en la imagen
    # volumes:
    #   - bitnet-cache:/app/cache
    
    # Puerto: 11435 externamente -> 8080 internamente
    ports:
      - "${BITNET_EXTERNAL_PORT:-11435}:8080"
    
    # Healthcheck con warm-up
    healthcheck:
      test: ["CMD", "/app/scripts/healthcheck.sh"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 180s  # 3 minutos para descarga inicial + carga en GPU
    
    # Logging
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "3"
    
    # Red
    networks:
      - bitnet-network
    
    # Reinicio automático
    restart: unless-stopped

  # ==========================================================================
  # SurrealDB (OPCIONAL) - Para RAG avanzado multi-usuario
  # Activar con: docker compose --profile rag up -d
  # ==========================================================================
  surrealdb:
    container_name: neuro-surrealdb
    image: surrealdb/surrealdb:latest
    profiles:
      - rag
    
    command: start --user root --pass root file:/data/rag.db
    
    volumes:
      - surrealdb-data:/data
    
    ports:
      - "${SURREALDB_PORT:-8000}:8000"
    
    networks:
      - bitnet-network
    
    restart: unless-stopped
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

# Red
networks:
  bitnet-network:
    driver: bridge

# Volúmenes
volumes:
  surrealdb-data:
    driver: local
