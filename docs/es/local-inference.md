---
layout: default
title: Inferencia Local
nav_order: 3
lang: es
---

# Inferencia Local con BitNet

ğŸŒ EspaÃ±ol | **[English](../local-inference)**

neuro-bitnet proporciona inferencia local **solo-CPU** usando modelos BitNet 1.58-bit de Microsoft. Estos modelos son extremadamente eficientes gracias a su cuantizaciÃ³n ternaria.

## CaracterÃ­sticas

- **Solo-CPU**: Optimizado especÃ­ficamente para procesadores modernos
- **Modelos BitNet**: Solo modelos de 1.58 bits de Microsoft
- **Auto-descarga**: Descarga automÃ¡tica de modelos con verificaciÃ³n SHA256
- **Streaming**: Respuestas en tiempo real con `--stream`
- **RAG integrado**: Combina con bÃºsqueda semÃ¡ntica y web

## Requisitos

### Compilar bitnet.cpp

Para usar inferencia local, necesitas compilar el runtime de bitnet.cpp:

```bash
# OpciÃ³n 1: Script automÃ¡tico (recomendado)
./scripts/setup_bitnet.sh

# OpciÃ³n 2: Manual
git clone https://github.com/microsoft/BitNet.git ~/.local/share/bitnet.cpp
cd ~/.local/share/bitnet.cpp
mkdir build && cd build
cmake .. -DGGML_BITNET_X86_TLS=ON
cmake --build . --config Release -j$(nproc)
mkdir -p ~/.local/bin
cp bin/llama-cli ~/.local/bin/llama-cli-bitnet
```

### Requisitos del Sistema

- **clang >= 18**: Necesario para las optimizaciones de 1.58 bits
- **cmake >= 3.14**

#### Ubuntu/Debian
```bash
sudo apt install clang-18 cmake build-essential
```

#### Arch Linux
```bash
sudo pacman -S clang cmake
```

#### macOS
```bash
brew install llvm cmake
export PATH="/opt/homebrew/opt/llvm/bin:$PATH"
```

## Modelos Soportados

| Modelo | TamaÃ±o | DescripciÃ³n | ID |
|--------|--------|-------------|-----|
| BitNet b1.58 2B-4T | 1.19 GB | Modelo principal, 2B params | `2b` |
| BitNet b1.58 Large | 0.7 GB | Modelo base 0.7B | `large` |
| BitNet b1.58 3B | 3.3 GB | Modelo grande 3B | `3b` |
| Llama3 8B 1.58 | 8 GB | Llama3 8B cuantizado a 1.58 bits | `8b` |

## Uso BÃ¡sico

### Descarga AutomÃ¡tica de Modelos

La primera vez que ejecutes `neuro ask`, se te preguntarÃ¡ si deseas descargar el modelo:

```bash
neuro ask "Â¿QuÃ© es BitNet?"

# Para saltar confirmaciÃ³n
neuro ask "Â¿QuÃ© es BitNet?" --yes

# Usar un modelo especÃ­fico
neuro ask "Â¿QuÃ© es BitNet?" --model 3b
```

### GestiÃ³n de Modelos

```bash
# Listar modelos disponibles
neuro model list

# Descargar un modelo especÃ­fico
neuro model download 2b

# Eliminar un modelo
neuro model remove 2b

# Ver informaciÃ³n del cache
neuro model info
```

### Con Streaming (respuesta en tiempo real)

```bash
neuro ask "Explica la teorÃ­a de la relatividad" --stream
```

### Con Contexto RAG

```bash
# Primero indexa algunos documentos
neuro index ./docs --recursive

# Luego pregunta con contexto
neuro ask "Resume la documentaciÃ³n" --storage ./data
```

### Con BÃºsqueda Web

```bash
neuro ask "Â¿CuÃ¡les son los Ãºltimos avances en IA?" --web
```

## ConfiguraciÃ³n

### Variables de Entorno

| Variable | Por defecto | DescripciÃ³n |
|----------|-------------|-------------|
| `BITNET_CLI_PATH` | Auto-detectar | Ruta al binario llama-cli |
| `NEURO_BITNET_MODELS_DIR` | `~/.cache/neuro-bitnet/models` | Directorio de cache de modelos |

### Opciones de CLI

```bash
neuro ask "pregunta" [OPCIONES]

Opciones:
  --model <NOMBRE>      Modelo a usar (2b, large, 3b, 8b) [default: 2b]
  --max-tokens <N>      MÃ¡ximo de tokens a generar [default: 512]
  --temperature <F>     Temperatura para muestreo [default: 0.7]
  --ctx-size <N>        TamaÃ±o de ventana de contexto [default: 4096]
  --threads <N>         NÃºmero de hilos [default: auto]
  --stream              Habilitar salida en streaming
  --yes                 Auto-confirmar descargas
  --web                 Habilitar contexto de bÃºsqueda web
  --storage <RUTA>      Ruta al almacenamiento RAG
  --timing              Mostrar informaciÃ³n de tiempos
  --verbose             Habilitar salida detallada
```

## Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         neuro-cli               â”‚
â”‚   (AplicaciÃ³n CLI en Rust)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      SubprocessBackend          â”‚
â”‚   (tokio::process::Command)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        llama-cli                â”‚
â”‚   (de bitnet.cpp)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Modelo BitNet GGUF         â”‚
â”‚   (cuantizaciÃ³n 1.58-bit)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## SoluciÃ³n de Problemas

### Binario no encontrado

```bash
# Verificar si existe el binario
which llama-cli-bitnet

# Establecer ruta manualmente
export BITNET_CLI_PATH="/ruta/a/llama-cli"
```

### Falla la descarga del modelo

```bash
# Eliminar descarga parcial
neuro model remove 2b

# Intentar de nuevo con flag force
neuro model download 2b --force
```

### Inferencia lenta

- AsegÃºrate de compilar con optimizaciÃ³n TLS: `-DGGML_BITNET_X86_TLS=ON`
- Usa menos hilos si la CPU estÃ¡ sobrecargada
- Considera usar un modelo mÃ¡s pequeÃ±o (2b en vez de 8b)

---

[â† Volver al Inicio](.) Â· [Benchmarks â†’](benchmarks)
